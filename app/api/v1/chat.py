from fastapi import APIRouter, HTTPException
from app.models.schemas import ChatRequest, ChatResponse
from app.services.llm_service import llm_service
from qdrant_client import QdrantClient
import traceback
import os

router = APIRouter()

# --- C·∫§U H√åNH RI√äNG CHO V1 ---
# B·∫Øt bu·ªôc d√πng Collection c≈© ƒë·ªÉ kh·ªõp v·ªõi Gemini Embedding (768 chi·ªÅu)
LEGACY_COLLECTION_NAME = "gym_food_collection"

# K·∫øt n·ªëi Qdrant tr·ª±c ti·∫øp (B·ªè qua vector_db service ƒë·ªÉ tr√°nh ƒë·ªçc nh·∫ßm .env)
QDRANT_HOST = os.getenv("QDRANT_HOST", "localhost")
QDRANT_PORT = int(os.getenv("QDRANT_PORT", 6333))
qdrant_client = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT)
SYSTEM_PROMPT = """
# ROLE (VAI TR√í)
B·∫°n l√† m·ªôt Chuy√™n gia Dinh d∆∞·ª°ng Th·ªÉ h√¨nh Th·ª±c chi·∫øn (Practical Gym Nutritionist).
Kh√°ch h√†ng c·ªßa b·∫°n l√† ng∆∞·ªùi t·∫≠p Gym c·∫ßn t∆∞ v·∫•n m√≥n ƒÉn c·ª• th·ªÉ ƒë·ªÉ b·ªè v√†o mi·ªáng, KH√îNG PH·∫¢I nh√† kho c·∫ßn ki·ªÉm k√™ nguy√™n li·ªáu.

# CRITICAL RULE: DATA TRANSLATION (QUY T·∫ÆC S·ªêNG C√íN - B·∫ÆT BU·ªòC)
D·ªØ li·ªáu trong CONTEXT l√† d·∫°ng th√¥ (Raw). B·∫°n TUY·ªÜT ƒê·ªêI KH√îNG hi·ªÉn th·ªã nguy√™n vƒÉn t√™n nguy√™n li·ªáu th√¥ ra m√†n h√¨nh. B·∫°n ph·∫£i th·ª±c hi·ªán b∆∞·ªõc "D·ªäCH D·ªÆ LI·ªÜU" theo logic sau:

1. T·ª™ ƒêI·ªÇN CHUY·ªÇN ƒê·ªîI (MAPPING):
   - Th·∫•y "G·∫°o t·∫ª/n·∫øp... s·ªëng" -> B·∫ÆT BU·ªòC ƒë·ªïi th√†nh: "C∆°m tr·∫Øng", "Ch√°o", ho·∫∑c "X√¥i".
   - Th·∫•y "Mi·∫øn/M√¨... kh√¥" -> B·∫ÆT BU·ªòC ƒë·ªïi th√†nh: "Mi·∫øn n·∫•u", "M√¨ lu·ªôc".
   - Th·∫•y "Khoai... kh√¥" -> ƒê·ªïi th√†nh: "Khoai lu·ªôc/h·∫•p".
   - Th·∫•y "B·ªôt..." -> Ch·ªâ g·ª£i √Ω n·∫øu c√≥ th·ªÉ l√†m th√†nh b√°nh (VD: B√°nh t·ª´ b·ªôt g·∫°o), n·∫øu kh√¥ng th√¨ B·ªé QUA.
   - Th·∫•y "Qu·∫£... kh√¥" -> Gi·ªØ nguy√™n (v√¨ ƒÉn li·ªÅn ƒë∆∞·ª£c).

2. X·ª¨ L√ù S·ªê LI·ªÜU (CALO/MACRO):
   - Gi·ªØ nguy√™n s·ªë li·ªáu Calo/Carb t·ª´ Context.
   - Th√™m ch√∫ th√≠ch nh·ªè: *(S·ªë li·ªáu t√≠nh tr√™n l∆∞·ª£ng nguy√™n li·ªáu th√¥ t∆∞∆°ng ·ª©ng)*.

# NUTRITION LOGIC (T∆Ø DUY DINH D∆Ø·ª†NG)
1. PH√ÇN LO·∫†I M·ª§C TI√äU:
   - V·ªõi m·ª•c ti√™u GI·∫¢M C√ÇN (Fat Loss): ∆Øu ti√™n Carb ti√™u h√≥a ch·∫≠m (Khoai, Y·∫øn m·∫°ch, ƒê·∫≠u), tr√°i c√¢y √≠t ƒë∆∞·ªùng. C·∫£nh b√°o c√°c m√≥n m·∫≠t ƒë·ªô nƒÉng l∆∞·ª£ng qu√° cao (nh∆∞ X√¥i, Hoa qu·∫£ s·∫•y nhi·ªÅu ƒë∆∞·ªùng).
   - V·ªõi m·ª•c ti√™u PRE-WORKOUT: Ch·ªçn m√≥n d·ªÖ ti√™u, gi√†u Carb ƒë·ªÉ n·∫°p nƒÉng l∆∞·ª£ng nhanh.

2. B·ªò L·ªåC TH·ª∞C T·∫æ (REALITY CHECK):
   - Tuy·ªát ƒë·ªëi kh√¥ng g·ª£i √Ω: M·ª≥ t√¥m (k√©m l√†nh m·∫°nh), G·∫°o s·ªëng (kh√¥ng ƒÉn ƒë∆∞·ª£c).

# OUTPUT FORMAT (ƒê·ªäNH D·∫†NG C√ÇU TR·∫¢ L·ªúI)
Tr√¨nh b√†y d∆∞·ªõi d·∫°ng Menu th·ª±c ƒë∆°n h·∫•p d·∫´n:

## üçΩÔ∏è Th·ª±c ƒë∆°n N·∫°p NƒÉng L∆∞·ª£ng Tr∆∞·ªõc T·∫≠p (Pre-Workout)
*(D·ª±a tr√™n d·ªØ li·ªáu dinh d∆∞·ª°ng)*

1. **[T√™n M√≥n ƒê√£ N·∫•u Ch√≠n]**
   - üìä Dinh d∆∞·ª°ng: [Calo] kcal | [Carb]g Carb | [Protein]g Pro
   - üí° T·∫°i sao ch·ªçn: [Gi·∫£i th√≠ch ng·∫Øn g·ªçn l·ª£i √≠ch cho vi·ªác t·∫≠p luy·ªán/gi·∫£m c√¢n]

2. **[T√™n M√≥n ƒÇn Li·ªÅn]**
   ...

‚ö†Ô∏è **L∆∞u √Ω quan tr·ªçng:** [L·ªùi khuy√™n v·ªÅ kh·∫©u ph·∫ßn ƒë·ªÉ ƒë·∫£m b·∫£o th√¢m h·ª•t Calo]
"""

@router.post("/chat", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest):
    try:
        print(f"--- [V1 Legacy] Nh·∫≠n c√¢u h·ªèi: {request.question} ---")
        
        # 1. T·∫°o vector b·∫±ng Gemini (Legacy method)
        # H√†m n√†y trong LLMService m·ªõi v·∫´n g·ªçi text-embedding-004 (768 chi·ªÅu)
        print("1. ƒêang t·∫°o vector Gemini (768 dims)...")
        query_vector = llm_service.get_embedding(request.question)
        
        if not query_vector:
            raise HTTPException(status_code=500, detail="L·ªói t·∫°o vector embedding.")

        # 2. T√¨m ki·∫øm trong Collection C≈© (gym_food_collection)
        print(f"2. ƒêang t√¨m trong collection: {LEGACY_COLLECTION_NAME}...")
        search_results = qdrant_client.search(
            collection_name=LEGACY_COLLECTION_NAME,
            query_vector=query_vector,
            limit=5
        )
        print(f"   -> T√¨m th·∫•y {len(search_results)} k·∫øt qu·∫£.")
        
        # 3. X√¢y d·ª±ng Context
        sources = []
        context_text = ""
        
        if not search_results:
            context_text = "Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu m√≥n ƒÉn n√†o ph√π h·ª£p."
        else:
            # Chuy·ªÉn ƒë·ªïi format Qdrant sang dict ƒë·ªÉ tr·∫£ v·ªÅ API
            context_items = []
            for hit in search_results:
                payload = hit.payload
                context_items.append(f"M√≥n: {payload.get('name')} - {payload.get('content')}")
                sources.append(payload) # L∆∞u l·∫°i source ƒë·ªÉ tr·∫£ v·ªÅ frontend
            
            context_text = "\n---\n".join(context_items)
        
        # 4. G·ª≠i cho LLM
        # D√π V1 c≈© d√πng Gemini, nh∆∞ng nh·ªù LLMService m·ªõi,
        # n√≥ s·∫Ω t·ª± ƒë·ªông d√πng Gemini ho·∫∑c Ollama t√πy theo b·∫°n set LLM_BACKEND trong .env
        # (R·∫•t ti·ªán: D·ªØ li·ªáu c≈© nh∆∞ng b·ªô n√£o tr·∫£ l·ªùi c√≥ th·ªÉ l√† Llama 3 m·ªõi)
        print("3. ƒêang sinh c√¢u tr·∫£ l·ªùi...")
        answer = llm_service.generate_response(
            system_prompt=SYSTEM_PROMPT,
            user_question=request.question,
            context=context_text
        )
        
        return ChatResponse(
            answer=answer,
            sources=sources
        )

    except Exception as e:
        print("-------------------- START ERROR TRACEBACK --------------------")
        traceback.print_exc() 
        print("-------------------- END ERROR TRACEBACK --------------------")
        raise HTTPException(status_code=500, detail=str(e))