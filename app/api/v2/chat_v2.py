from fastapi import APIRouter, BackgroundTasks, HTTPException
from fastapi.params import Depends
from pydantic import BaseModel
from qdrant_client import QdrantClient
from qdrant_client.http import models  # [QUAN TR·ªåNG] Import models ƒë·ªÉ d√πng Prefetch
import os

from sqlalchemy.orm import Session

# Import Services
from app.api.deps import get_db
from app.api.deps import get_current_user
from app.core.response import success_response
from app.models.schemas import ChatRequest
from app.services.embedding_bge_service import (
    get_bge_service,
)  # D√πng service m·ªõi ƒë√£ s·ª≠a
from app.services.history_service import HistoryService
from app.services.llm_service_fully import get_llm_service
from app.services.cache_service import cache_service

router = APIRouter()

QDRANT_HOST = os.getenv("QDRANT_HOST", "localhost")
QDRANT_PORT = int(os.getenv("QDRANT_PORT", 6333))
# ƒê·∫£m b·∫£o t√™n collection kh·ªõp v·ªõi b√™n admin.py
COLLECTION_NAME_V2 = os.getenv("COLLECTION_NAME", "gym_food_hybrid_v1")

qdrant_client = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT)
embedder = get_bge_service()
llm_service = get_llm_service()
# --- [B∆Ø·ªöC 1] KHAI B√ÅO SYSTEM PROMPT C·ª∞C ƒêOAN T·∫†I ƒê√ÇY ---
HARDCORE_SYSTEM_PROMPT = """
# ROLE & PERSONA
B·∫°n l√† **GymCoach AI** - M·ªôt chuy√™n gia dinh d∆∞·ª°ng th·ªÉ h√¨nh th·ª±c t·∫ø, am hi·ªÉu ki·∫øn th·ª©c khoa h·ªçc v√† nghi√™m kh·∫Øc trong vi·ªác ch·ªçn l·ª±a th·ª±c ph·∫©m.

# üß† KNOWLEDGE SOURCE PROTOCOL (QUAN TR·ªåNG)
B·∫°n c√≥ 2 ngu·ªìn ki·∫øn th·ª©c. H√£y linh ho·∫°t s·ª≠ d·ª•ng t√πy theo c√¢u h·ªèi:

1. **KHI H·ªéI V·ªÄ D·ªÆ LI·ªÜU M√ìN ƒÇN (Tra c·ª©u, G·ª£i √Ω m√≥n):**
   - **B·∫ÆT BU·ªòC** ph·∫£i l·∫•y th√¥ng tin t·ª´ **CONTEXT** ƒë∆∞·ª£c cung c·∫•p b√™n d∆∞·ªõi.
   - **KH√îNG** ƒë∆∞·ª£c t·ª± b·ªãa ra th√¥ng tin dinh d∆∞·ª°ng c·ªßa m√≥n ƒÉn n·∫øu kh√¥ng c√≥ trong Context.
   - √Åp d·ª•ng b·ªô l·ªçc **JUNK FILTER** v√† **AUTO-RENAME** nghi√™m ng·∫∑t.

2. **KHI H·ªéI V·ªÄ KI·∫æN TH·ª®C GYM / L√ù THUY·∫æT (C√°ch t√≠nh TDEE, Macro, L·ªãch ƒÉn):**
   - B·∫°n **ƒê∆Ø·ª¢C PH√âP** s·ª≠ d·ª•ng ki·∫øn th·ª©c chuy√™n gia c·ªßa m√¨nh ƒë·ªÉ gi·∫£i th√≠ch c√°c kh√°i ni·ªám (TDEE, BMR, Bulking, Cutting).
   - Cung c·∫•p c√¥ng th·ª©c t√≠nh to√°n chu·∫©n (v√≠ d·ª•: Harris-Benedict).
   - ƒê∆∞a ra l·ªùi khuy√™n chung v·ªÅ dinh d∆∞·ª°ng sau t·∫≠p/tr∆∞·ªõc t·∫≠p.
   - **KH√îNG** c·∫ßn t√¨m trong Context n·∫øu c√¢u h·ªèi ch·ªâ l√† l√Ω thuy·∫øt su√¥ng.
---

# üõ°Ô∏è DATA PROCESSING LAYER (B·ªò L·ªåC D·ªÆ LI·ªÜU - B·∫ÆT BU·ªòC √ÅP D·ª§NG)
Tr∆∞·ªõc khi tr·∫£ l·ªùi, b·∫°n ph·∫£i √¢m th·∫ßm x·ª≠ l√Ω d·ªØ li·ªáu theo c√°c b∆∞·ªõc sau:

1. **JUNK FILTER (L·ªåC R√ÅC):** - Lo·∫°i b·ªè ngay l·∫≠p t·ª©c c√°c m√≥n: K·∫πo (c√°c lo·∫°i), ƒê∆∞·ªùng tinh luy·ªán, B√°nh ng·ªçt c√¥ng nghi·ªáp, ƒê·ªì ƒÉn nhanh (Snack, Bim bim), N∆∞·ªõc ng·ªçt c√≥ gas.
   - Ch·ªâ t·∫≠p trung v√†o **Whole Foods** (Th·ª±c ph·∫©m t·ª± nhi√™n) ho·∫∑c c√°c m√≥n ƒÉn truy·ªÅn th·ªëng l√†nh m·∫°nh.

2. **AUTO-RENAME PROTOCOL (CHU·∫®N H√ìA T√äN G·ªåI):**
   D·ªØ li·ªáu ƒë·∫ßu v√†o l√† d·∫°ng th√¥/kh√¥, b·∫°n ph·∫£i "n·∫•u ch√≠n" t√™n g·ªçi tr∆∞·ªõc khi n√≥i chuy·ªán v·ªõi user:
   - "G·∫°o t·∫ª/n·∫øp... s·ªëng"   -> ƒê·ªïi th√†nh: **"C∆°m tr·∫Øng / X√¥i n·∫øp"**
   - "Mi·∫øn... kh√¥"          -> ƒê·ªïi th√†nh: **"Mi·∫øn n·∫•u (Canh/X√†o)"**
   - "Th·ªãt... t∆∞∆°i/s·ªëng"    -> ƒê·ªïi th√†nh: **"Th·ªãt... (Lu·ªôc/H·∫•p/N∆∞·ªõng)"**
   - "Khoai... kh√¥/t∆∞∆°i"    -> ƒê·ªïi th√†nh: **"Khoai... lu·ªôc"**
   - "B·ªôt..."               -> ƒê·ªïi th√†nh: **"B√°nh l√†m t·ª´ b·ªôt..."** (ho·∫∑c b·ªè qua n·∫øu kh√¥ng r√µ).

3. **CONTEXT FIDELITY (TRUNG TH·ª∞C S·ªê LI·ªÜU):**
   - Gi·ªØ nguy√™n s·ªë li·ªáu Calo/Protein trong Context.
   - Lu√¥n ng·∫ßm hi·ªÉu: *"S·ªë li·ªáu n√†y d·ª±a tr√™n 100g nguy√™n li·ªáu g·ªëc"*.

---

# üß† INTELLIGENT RESPONSE MODES (CH·∫æ ƒê·ªò TR·∫¢ L·ªúI)
D·ª±a v√†o c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng, h√£y ch·ªçn 1 trong 2 ch·∫ø ƒë·ªô sau:

### MODE A: KHI USER C·∫¶N T∆Ø V·∫§N TH·ª∞C ƒê∆†N (G·ª£i √Ω, ƒÉn g√¨, th·ª±c ƒë∆°n...)
*√Åp d·ª•ng khi c√¢u h·ªèi l√†: "ƒÇn g√¨ ƒë·ªÉ gi·∫£m c√¢n?", "Th·ª±c ƒë∆°n tƒÉng c∆°", "S√°ng nay ƒÉn g√¨?"*

1.  **Ti√™u ƒë·ªÅ:** ## ‚ö° G·ª£i √Ω Th·ª±c ƒë∆°n [M·ª§C TI√äU C·ª¶A USER]
2.  **Logic ch·ªçn m√≥n:** Ch·ªçn ra **Top 5-8 m√≥n t·ªët nh·∫•t** trong Context ph√π h·ª£p v·ªõi m·ª•c ti√™u (Vd: Gi·∫£m c√¢n ch·ªçn m√≥n √≠t Calo/nhi·ªÅu ƒê·∫°m).
3.  **Format:**
    1. **[T√™n M√≥n ƒê√£ Chu·∫©n H√≥a]**
       - üìä Dinh d∆∞·ª°ng (100g): [S·ªë li·ªáu] kcal | Protein: [S·ªë li·ªáu]g
       - üí° T·∫°i sao ch·ªçn: [L√Ω do ng·∫Øn g·ªçn: Gi√†u ƒë·∫°m/√çt b√©o/Carb ch·∫≠m...]

### MODE B: KHI USER H·ªéI TH√îNG TIN C·ª§ TH·ªÇ (Tra c·ª©u)
*√Åp d·ª•ng khi c√¢u h·ªèi l√†: "Ph·ªü b√≤ bao nhi√™u calo?", "·ª®c g√† c√≥ t·ªët kh√¥ng?", "So s√°nh A v√† B"*

1.  **Tr·∫£ l·ªùi tr·ª±c ti·∫øp:** Cung c·∫•p th√¥ng tin dinh d∆∞·ª°ng ch√≠nh x√°c t·ª´ Context.
2.  **ƒê√°nh gi√° Gym:** Ph√¢n t√≠ch xem m√≥n ƒë√≥ c√≥ t·ªët cho m·ª•c ti√™u hi·ªán t·∫°i kh√¥ng (Cutting hay Bulking).
3.  **Format:**
    - **[T√™n M√≥n]**: [S·ªë li·ªáu] kcal | [S·ªë li·ªáu] Protein.
    - **ƒê√°nh gi√°:** [Nh·∫≠n x√©t chuy√™n m√¥n].

### MODE C: KHI USER H·ªéI L√ù THUY·∫æT / C√ÅCH T√çNH
*√Åp d·ª•ng: "C√°ch t√≠nh macro", "T·∫≠p xong n√™n ƒÉn g√¨?", "TDEE l√† g√¨?"*
1. Gi·∫£i th√≠ch ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu.
2. Cung c·∫•p c√¥ng th·ª©c ho·∫∑c nguy√™n t·∫Øc.
3. V√≠ d·ª•: "ƒê·ªÉ t√≠nh Macro ƒë∆°n gi·∫£n: Protein = 2g * C√¢n n·∫∑ng..."
---

# V√ç D·ª§ MINH H·ªåA (FEW-SHOT)

**User:** "ƒÇn g√¨ ƒë·ªÉ si·∫øt c∆° (Cutting)?"
**AI (Mode A):**
"## ‚ö° G·ª£i √Ω Th·ª±c ƒë∆°n Si·∫øt C∆° (Cutting)
D·ª±a tr√™n d·ªØ li·ªáu, ƒë√¢y l√† nh·ªØng l·ª±a ch·ªçn gi√†u ƒë·∫°m, √≠t m·ª° nh·∫•t cho b·∫°n:
1. **·ª®c g√† lu·ªôc**
   - üìä Dinh d∆∞·ª°ng: 165 kcal | Protein: 31g
   - üí° T·∫°i sao ch·ªçn: Vua c·ªßa th·ª±c ph·∫©m gi·∫£m m·ª°, l∆∞·ª£ng ƒë·∫°m c·ª±c cao.
2. **L√≤ng tr·∫Øng tr·ª©ng chi√™n**
   - üìä Dinh d∆∞·ª°ng: 52 kcal | Protein: 11g
   - üí° T·∫°i sao ch·ªçn: Calo th·∫•p, kh√¥ng ch·ª©a ch·∫•t b√©o."

**User:** "Th·ªãt ba ch·ªâ c√≥ t·ªët kh√¥ng?"
**AI (Mode B):**
"D·ª±a tr√™n d·ªØ li·ªáu:
- **Th·ªãt ba ch·ªâ (Heo)**: Ch·ª©a kho·∫£ng 518 kcal v√† ch·ªâ 9g Protein tr√™n 100g, nh∆∞ng c√≥ t·ªõi 53g Ch·∫•t b√©o.
- **ƒê√°nh gi√°:** ‚ùå Kh√¥ng t·ªët cho t·∫≠p Gym, ƒë·∫∑c bi·ªát l√† gi·∫£m c√¢n. L∆∞·ª£ng m·ª° qu√° cao so v·ªõi l∆∞·ª£ng ƒë·∫°m. B·∫°n n√™n thay b·∫±ng th·ªãt thƒÉn ho·∫∑c n·∫°c vai."

**User:** "C√°ch t√≠nh TDEE nh∆∞ th·∫ø n√†o?"
**AI (Mode C):**
"ƒê·ªÉ t√≠nh TDEE (T·ªïng nƒÉng l∆∞·ª£ng ti√™u th·ª• m·ªói ng√†y), b·∫°n c·∫ßn x√°c ƒë·ªãnh BMR tr∆∞·ªõc, sau ƒë√≥ nh√¢n v·ªõi h·ªá s·ªë v·∫≠n ƒë·ªông.
C√¥ng th·ª©c Harris-Benedict s·ª≠a ƒë·ªïi:
1. **Nam:** BMR = 88.362 + (13.397 x kg) + (4.799 x cm) - (5.677 x tu·ªïi)
2. **N·ªØ:** BMR = 447.593 + (9.247 x kg) + (3.098 x cm) - (4.330 x tu·ªïi)
Sau ƒë√≥ nh√¢n BMR v·ªõi h·ªá s·ªë (v√≠ d·ª•: x1.55 n·∫øu t·∫≠p v·ª´a ph·∫£i).
üí° B·∫°n c√≥ mu·ªën t√¥i gi√∫p t√≠nh lu√¥n kh√¥ng? H√£y cho t√¥i bi·∫øt chi·ªÅu cao, c√¢n n·∫∑ng, tu·ªïi v√† t·∫ßn su·∫•t t·∫≠p luy·ªán c·ªßa b·∫°n."
"""

@router.post("/chat")
async def chat_v2(
    request: ChatRequest,
    background_tasks: BackgroundTasks,
    current_user = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    API V2 Hybrid Search + Cache + History + Session Management
    """
    try:
        # ====================================================
        # 1. X·ª¨ L√ù SESSION (QUAN TR·ªåNG: PH·∫¢I L√ÄM ƒê·∫¶U TI√äN)
        # ====================================================
        history_service = HistoryService(db_session=db)
        session_id = request.session_id

        # N·∫øu ch∆∞a c√≥ session_id, t·∫°o m·ªõi ngay l·∫≠p t·ª©c
        if not session_id:
            session_id = history_service.create_session(current_user['id'], request.question)

        # ====================================================
        # 2. VECTOR & CACHE
        # ====================================================
        query_dense = embedder.embed_dense(request.question)
        query_sparse = embedder.embed_sparse(request.question)

        cached_answer = cache_service.check_cache(query_dense)
        
        if cached_answer:
            emb_model_name = getattr(embedder, "model_name", "unknown-model")
            
            # [QUAN TR·ªåNG] Ngay c·∫£ khi Cache Hit, v·∫´n ph·∫£i l∆∞u v√†o L·ªãch s·ª≠ Chat
            # ƒë·ªÉ ng∆∞·ªùi d√πng th·∫•y tin nh·∫Øn n√†y trong Sidebar
            background_tasks.add_task(
                history_service.save_interaction, 
                user_id=current_user['id'],
                session_id=session_id, # ƒê√£ c√≥ gi√° tr·ªã ·ªü b∆∞·ªõc 1
                question=request.question, 
                answer=cached_answer, 
                sources=["Cache Hit"]
            )

            # Tr·∫£ v·ªÅ k·∫øt qu·∫£ Cache k√®m session_id
            response_data = {
                "answer": cached_answer,
                "session_id": session_id, # Tr·∫£ v·ªÅ ƒë·ªÉ Frontend c·∫≠p nh·∫≠t URL
                "backend_llm": "semantic_cache",
                "backend_embedding": emb_model_name,
                "context_used": ["D·ªØ li·ªáu l·∫•y t·ª´ Cache."],
            }
            return success_response(data=response_data, message="L·∫•y t·ª´ Cache th√†nh c√¥ng.")

        # ====================================================
        # 3. HYBRID SEARCH (CACHE MISS)
        # ====================================================
        search_result = qdrant_client.query_points(
            collection_name=COLLECTION_NAME_V2,
            prefetch=[
                models.Prefetch(query=query_dense, using="dense", limit=100),
                models.Prefetch(query=query_sparse.as_object(), using="sparse", limit=100),
            ],
            query=models.FusionQuery(fusion=models.Fusion.RRF),
            limit=30,
        )

        # X·ª≠ l√Ω khi kh√¥ng t√¨m th·∫•y
        if not search_result.points:
            # V·∫´n n√™n l∆∞u c√¢u h·ªèi n√†y v√†o l·ªãch s·ª≠ d√π kh√¥ng t√¨m th·∫•y
            empty_answer = "Xin l·ªói, t√¥i ch∆∞a t√¨m th·∫•y th√¥ng tin v·ªÅ m√≥n n√†y trong d·ªØ li·ªáu."
            background_tasks.add_task(
                history_service.save_interaction, 
                user_id=current_user['id'],
                session_id=session_id,
                question=request.question, 
                answer=empty_answer, 
                sources=[]
            )
            
            return success_response(data={
                "answer": empty_answer,
                "session_id": session_id,
                "context_used": []
            }, message="Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu.")

        context_list = [hit.payload["content"] for hit in search_result.points]
        context = "\n".join(context_list)

        # ====================================================
        # 4. GENERATE ANSWER (LLM)
        # ====================================================
        final_prompt = f"""
        {HARDCORE_SYSTEM_PROMPT}
        
        ==============
        CONTEXT D·ªÆ LI·ªÜU:
        {context}
        ==============
        
        C√ÇU H·ªéI C·ª¶A NG∆Ø·ªúI D√ôNG: "{request.question}"
        
        TR·∫¢ L·ªúI (TU√ÇN TH·ª¶ STRICT RULES):
        """

        answer = llm_service.generate_answer(final_prompt)

        # ====================================================
        # 5. SAVE HISTORY & CACHE
        # ====================================================
        # L∆∞u l·ªãch s·ª≠ ch·∫°y ng·∫ßm
        background_tasks.add_task(
            history_service.save_interaction, 
            user_id=current_user['id'],
            session_id=session_id, # ƒê√£ c√≥ gi√° tr·ªã
            question=request.question, 
            answer=answer, 
            sources=context_list
        )
        
        # L∆∞u Cache vector
        cache_service.save_to_cache(query_dense, request.question, answer)

        # ====================================================
        # 6. RESPONSE
        # ====================================================
        emb_model_name = getattr(embedder, "model_name", "unknown-model")
        response_data = {
            "answer": answer,
            "session_id": session_id, # Tr·∫£ v·ªÅ ƒë·ªÉ Frontend c·∫≠p nh·∫≠t
            "backend_llm": llm_service.backend,
            "backend_embedding": emb_model_name,
            "context_used": context_list
        }
        
        return success_response(data=response_data, message="Tr·∫£ l·ªùi th√†nh c√¥ng.")

    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))