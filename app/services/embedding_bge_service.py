# import os
# from typing import List
# import torch
# from sentence_transformers import SentenceTransformer
# from dotenv import load_dotenv

# load_dotenv()

# class BGEEmbeddingService:
#     """
#     Service V2: ChuyÃªn dá»¥ng cho model BAAI/bge-m3 (FlagEmbedding).
#     Output Dimension: 1024
#     """
#     def __init__(self):
#         # Hardcode model tá»‘t nháº¥t hoáº·c láº¥y tá»« ENV nhÆ°ng default lÃ  BGE-M3
#         self.model_name = os.getenv("V2_EMBEDDING_MODEL", "BAAI/bge-m3")
#         print(f"ðŸš€ [API v2] Äang khá»Ÿi táº¡o BGE-M3 Model: {self.model_name}...")
        
#         device = "cuda" if torch.cuda.is_available() else "cpu"
#         print(f"âš™ï¸ [API v2] Running on device: {device.upper()}")
        
#         try:
#             self.model = SentenceTransformer(self.model_name, device=device)
#             # BGE-M3 há»— trá»£ fp16 giÃºp giáº£m 50% RAM/VRAM mÃ  khÃ´ng giáº£m cháº¥t lÆ°á»£ng
#             if device == "cuda":
#                 self.model.half()
#             print("âœ… [API v2] BGE-M3 Ready!")
#         except Exception as e:
#             print(f"âŒ [API v2] Error loading model: {e}")
#             raise e

#     def embed_query(self, text: str) -> List[float]:
#         """
#         DÃ nh cho cÃ¢u há»i cá»§a user.
#         BGE-M3 khÃ´ng báº¯t buá»™c prefix 'query:', nhÆ°ng thÃªm vÃ o cÅ©ng tá»‘t.
#         """
#         # BGE-M3 tá»± Ä‘á»™ng xá»­ lÃ½ ráº¥t tá»‘t, ta dÃ¹ng dense vector (output Ä‘áº§u tiÃªn)
#         embeddings = self.model.encode(
#             [text], 
#             convert_to_numpy=True, 
#             normalize_embeddings=True
#         )
#         return embeddings[0].tolist()

#     def embed_document(self, text: str) -> List[float]:
#         """DÃ nh cho viá»‡c náº¡p dá»¯ liá»‡u vÃ o DB"""
#         embeddings = self.model.encode(
#             [text], 
#             convert_to_numpy=True, 
#             normalize_embeddings=True
#         )
#         return embeddings[0].tolist()

# # Singleton instance
# # Chá»‰ khá»Ÿi táº¡o khi Ä‘Æ°á»£c gá»i import Ä‘á»ƒ tiáº¿t kiá»‡m tÃ i nguyÃªn náº¿u chÆ°a dÃ¹ng tá»›i
# _service_instance = None

# def get_bge_service():
#     global _service_instance
#     if _service_instance is None:
#         _service_instance = BGEEmbeddingService()
#     return _service_instance


import os
from typing import List
import torch
from sentence_transformers import SentenceTransformer
from dotenv import load_dotenv
# ThÃªm import nÃ y
from fastembed import SparseTextEmbedding

load_dotenv()

class BGEEmbeddingService:
    def __init__(self):
        # 1. Load Model Dense (NhÆ° cÅ©)
        self.model_name = os.getenv("V2_EMBEDDING_MODEL", "BAAI/bge-m3")
        print(f"ðŸš€ [Dense] Loading BGE-M3: {self.model_name}...")
        device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model = SentenceTransformer(self.model_name, device=device)
        if device == "cuda": self.model.half()
        
        # 2. Load Model Sparse (Má»šI) - DÃ¹ng SPLADE ráº¥t nháº¹
        print(f"ðŸš€ [Sparse] Loading SPLADE for Keywords...")
        self.sparse_model = SparseTextEmbedding(model_name="prithivida/Splade_PP_en_v1")
        print("âœ… [Embedding] Hybrid Models Ready!")

    def embed_dense(self, text: str) -> List[float]:
        """Táº¡o Dense Vector (Ngá»¯ nghÄ©a)"""
        embeddings = self.model.encode([text], convert_to_numpy=True, normalize_embeddings=True)
        return embeddings[0].tolist()

    def embed_sparse(self, text: str):
        """Táº¡o Sparse Vector (Tá»« khÃ³a) - Má»šI"""
        # fastembed tráº£ vá» generator, ta láº¥y pháº§n tá»­ Ä‘áº§u tiÃªn
        return list(self.sparse_model.embed([text]))[0]

    # Giá»¯ láº¡i hÃ m cÅ© Ä‘á»ƒ trÃ¡nh lá»—i code cÅ©, trá» vá» embed_dense
    def embed_query(self, text: str) -> List[float]:
        return self.embed_dense(text)

    def embed_document(self, text: str) -> List[float]:
        return self.embed_dense(text)

# Singleton
_service_instance = None
def get_bge_service():
    global _service_instance
    if _service_instance is None:
        _service_instance = BGEEmbeddingService()
    return _service_instance